{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to generate Adult Data and pass it in self.data\n",
    "<ul>\n",
    "    <li>Need ask best params from Rosin</li>\n",
    "    <li> run Adult\n",
    "    <li> Save data from PreProcessing somewhere\n",
    "    <li> Wrap to take two csv of corresponding original (label)\n",
    "    <li> Code test testing loop\n",
    "    <li> What to use as test loss and final metric\n",
    "    <li> Same Encoding\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *** \n",
      " Currently running on cpu\n",
      " *** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Imports\n",
    "import utilities as utils\n",
    "# import datasets as d\n",
    "\n",
    "# from Stats import Plots as Pl\n",
    "import tqdm\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import os.path\n",
    "import warnings\n",
    "import importlib\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from torch.utils.data import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data as td\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CPU_DEVICE = torch.device(\"cpu\")\n",
    "GET_VALUE = lambda x: x.to(CPU_DEVICE).data.numpy().reshape(-1)[0]\n",
    "print(f\"\\n *** \\n Currently running on {DEVICE}\\n *** \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import & Pre-processing\n",
    "  \n",
    "class My_dataLoader:\n",
    "    def __init__(self, batch_size : int, path :str, n_train :int,  label_col_name:str, test_batch_size:int=128):\n",
    "        '''\n",
    "            Creates train and test loaders from local files, to be easily used by torch.nn\n",
    "            \n",
    "            :batch_size: int for size of training batches\n",
    "            :path: path to csv where data is. 2d file, where last value of each cols\n",
    "                    is the label\n",
    "            :n_train: int for the size of training set (assigned randomly)\n",
    "            :test_batch: size of batches at test time. If none, will be same \n",
    "                    as training\n",
    "            :label_col_name name of columns that contains labels\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.train_size = n_train\n",
    "        self.test_batch = test_batch_size\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        \n",
    "        a = df.values\n",
    "        self.data = torch.tensor(a[:,:-1]) # where data is 2d [D_train_size x features]\n",
    "        self.labels = torch.tensor(a[:,-1])\n",
    "        \n",
    "        self.local_dataset = torch.utils.data.TensorDataset(self.data, self.labels)\n",
    "                     \n",
    "        #custom_transform = transforms.Normalize((mean_mean,), (std_mean,)) \n",
    "        \n",
    "        \n",
    "        indices = list(range(len(self.local_dataset)))\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        # Split dataset into train and Test sets\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.local_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=SubsetRandomSampler(indices[:self.train_size]),\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "        self.test_loader = DataLoader(\n",
    "            self.local_dataset,\n",
    "            batch_size=self.test_batch,\n",
    "            sampler=SubsetRandomSampler(indices[self.train_size:]),\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "class PreProcessing:\n",
    "    def __init__(self, params_file: str):\n",
    "        '''\n",
    "            Imports all variables/parameters necessary for preparation of training.\n",
    "            Looks into params.yaml, then creates dataloader that can be used\n",
    "            \n",
    "            params_file: path to file that contains parameters.\n",
    "                            Needs to follow a specific naming and format\n",
    "        '''\n",
    "        # Import params\n",
    "        stream = open(params_file, 'r')\n",
    "        data = yaml.load(stream, yaml.FullLoader)\n",
    "\n",
    "        import_path = data['data_loading']['path']['value']\n",
    "\n",
    "        batchSize = data['model_params']['batchSize']['value']\n",
    "        test_batch_size = data['model_params']['test_batch_size']['value']\n",
    "        percent_train_set = data['model_params']['percent_train_set']['value']\n",
    "\n",
    "\n",
    "        df2 = pd.read_csv(import_path+\".csv\")\n",
    "        n_test = int(len(df2.iloc[:,0])*percent_train_set)\n",
    "\n",
    "        # Check for categorical variables\n",
    "        cat_list = utils.find_cat(df2)\n",
    "\n",
    "        if len(cat_list) > 0:\n",
    "            print(f\"Categorical variable found. Running Pandas dummy_variable encoding on {len(cat_list)} columns \\n\")\n",
    "            df2 = utils.dummy_encode(df2, cat_list)\n",
    "            print(f\"Saving output dataset under {import_path}_NoCat.csv \\n\")\n",
    "            df2.to_csv(f\"{import_path}_NoCat.csv\", index=False)\n",
    "            self.dataloader = My_dataLoader(batchSize, f\"{import_path}_NoCat.csv\", n_test, \"income\", test_batch_size)\n",
    "        \n",
    "        else: # no categorical vars found\n",
    "            self.dataloader = My_dataLoader(batchSize, import_path+'.csv', n_test, \"income\", test_batch_size)\n",
    "        \n",
    "        # Save data somewhere\n",
    "#         1 - make dir inside experimetns with copy of params.yaml\n",
    "#         2- dump json with other info in there\n",
    "#         dataset_name = data['data_loading']['path']['value'].split('/')[-1]\n",
    "        \n",
    "#         with open(f'./experiments/{dataset_name}_{}.txt', 'w') as file:\n",
    "#              file.write(json.dumps(exDict))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variable found. Running Pandas dummy_variable encoding on: \n",
      " [['Status_of_existing_checking_account', 'Credit_history', 'Purpose', 'Savings_account_bonds', 'Present_employment_since', 'Personal_status_and_sex', '_Other_debtors_or_guarantors', 'Property', 'Other_installment_plans', 'Housing', 'Job', 'foreign_worker']] \n",
      "\n",
      "Saving output dataset under ../GeneralDatasets/sanitizer_output/german_credit/n=1_alpha-gr-0.9_NoCat.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = PreProcessing(\"params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, out_dim), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = None\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "#######\n",
    "in_dim = len(df2.iloc[0,:])\n",
    "out_dim = len(df2.iloc[0,:])\n",
    "#######\n",
    "\n",
    "model = autoencoder(in_dim, out_dim).cuda()\n",
    "train_loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader.train_data:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).cuda()\n",
    "        # Fprop\n",
    "        output = model(img)\n",
    "        loss = train_loss(output, img)\n",
    "        # bprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        NEED TEST SET\n",
    "        \n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
