{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Need to generate Adult Data and pass it in self.data\n",
    "<ul>\n",
    "   <li>Need ask best params from Rosin</li>\n",
    "    <li>\n",
    "</ul>\n",
    "### 2- in Dataloader class, self.labels can be directly the original as 2d tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# from Modules import setup as s\n",
    "# from Modules import utils as u\n",
    "# from Modules import plots as pl\n",
    "# from Modules import models as m\n",
    "# from Modules import Results as r\n",
    "import datasets as d\n",
    "# from Modules import metrics_ as me\n",
    "# from Modules import customLosses as cl\n",
    "# from Modules import analysisTools as at\n",
    "# from Modules import optimizers2 as optim\n",
    "# from Parameters import parameters as p\n",
    "\n",
    "# from Stats import Plots as Pl\n",
    "import tqdm\n",
    "import torch\n",
    "import warnings\n",
    "import importlib\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from torch.utils.data import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data as td\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CPU_DEVICE = torch.device(\"cpu\")\n",
    "GET_VALUE = lambda x: x.to(CPU_DEVICE).data.numpy().reshape(-1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import & Pre-processing\n",
    "\n",
    "def dummy_encode(df: pd.core.frame.DataFrame, cat_cols : List[str] ) -> pd.core.frame.DataFrame:\n",
    "    '''\n",
    "        Will first look for categorical variable (strings) in each columns' first value, \n",
    "        then encode the categorical columns in one-hot using pandas dummy encoding\n",
    "        \n",
    "        :param df: Dataframe to work with\n",
    "        :param cat_cols: list of columns that needs to be changed \n",
    "        \n",
    "        :return same dataframe, encoded if required\n",
    "        \n",
    "    '''\n",
    "    if cat_cols == 0:\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        return(pd.get_dummies(df2, columns=cat_cols))\n",
    "    \n",
    "\n",
    "def find_cat(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    cat_cols = []\n",
    "    for col_name, col_data in df.iteritems():\n",
    "        if type(col_data.values[0]) == str:\n",
    "            cat_cols.append(col_name)\n",
    "\n",
    "    return cat_cols\n",
    "            \n",
    "class My_dataLoader:\n",
    "    def __init__(self, batch_size : int, path :str, n_train :int, test_batch:int = None, label_col_name:str):\n",
    "        '''\n",
    "            Creates train and test loaders from local files, to be easily used by torch.nn\n",
    "            \n",
    "            :batch_size: int for size of training batches\n",
    "            :path: path to csv where data is. 2d file, where last value of each cols\n",
    "                    is the label\n",
    "            :n_train: int for the size of training set (assigned randomly)\n",
    "            :test_batch: size of batches at test time. If none, will be same \n",
    "                    as training\n",
    "            :label_col_name name of columns that contains labels\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.n_test = n_test\n",
    "\n",
    "        batch_size_eval = 128\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        \n",
    "        a = df.values\n",
    "        self.data = torch.tensor(a[:,:-1]) # where data is 2d [D_train_size x features]\n",
    "        self.labels = torch.tensor(a[:,-1])\n",
    "        \n",
    "        self.local_dataset = torch.utils.data.TensorDataset(self.data, self.labels)\n",
    "                     \n",
    "        #custom_transform = transforms.Normalize((mean_mean,), (std_mean,)) \n",
    "        \n",
    "        \n",
    "        indices = list(range(len(self.local_dataset)))\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        # Split dataset into train and Test sets\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.local_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=SubsetRandomSampler(indices[:n_test]),\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "        self.test_loader = DataLoader(\n",
    "            self.local_dataset,\n",
    "            batch_size=batch_size_eval,\n",
    "            sampler=SubsetRandomSampler(indices[n_test:]),\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "        \n",
    "# Create the object with both loader and loss functions\n",
    "batchSize = 32\n",
    "\n",
    "# dataloader = My_dataLoader(batchSize, path, n_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "import_path = \"../GeneralDatasets/Csv/Adult_NoCat\"\n",
    "df2 = pd.read_csv(import_path+\".csv\")\n",
    "n_test = int(len(df2.iloc[:,0])*0.85) # keep 15% for test set\n",
    "\n",
    "# Encode Categorical Vars\n",
    "cat_list = find_cat(df2)\n",
    "\n",
    "\n",
    "if len(cat_list) > 0:\n",
    "    print(f\"Categorical variable found. Running Pandas dummy_variable encoding on: \\n [{cat_list}] \\n\")\n",
    "    df2 = dummy_encode(df2, cat_list)\n",
    "    print(f\"Saving output dataset under {import_path}_NoCat.csv \\n\")\n",
    "    df2.to_csv(f\"{import_path}_NoCat.csv\", index=False)\n",
    "# Load data\n",
    "    data_loader = My_dataLoader(batchSize, f\"{import_path}_NoCat.csv\", n_test, \"income\")\n",
    "else:\n",
    "    data_loader = My_dataLoader(batchSize, import_path+'.csv', n_test, \"income\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# group_attributes = [\"label\"]  # Protected or sensitive attribute\n",
    "\n",
    "# # TODO: Change what is put as labels, if I want to use pytorch loss. Might have to deal with L1 calculation manually\n",
    "# d_ = d.TorchGeneralDataset(\"../test.csv\", target_feature=group_attributes[0],\n",
    "#                                        xTensor=torch.FloatTensor, yTensor=torch.LongTensor,\n",
    "#                                        transform=None,\n",
    "#                      )\n",
    "\n",
    "# l_d = td.DataLoader(d_, batch_size=d_i.df.shape[0], shuffle=False, num_workers=p.Num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, out_dim), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = None\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "#######\n",
    "in_dim = len(df2.iloc[0,:])\n",
    "out_dim = len(df2.iloc[0,:])\n",
    "#######\n",
    "\n",
    "model = autoencoder(in_dim, out_dim).cuda()\n",
    "train_loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader.train_data:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).cuda()\n",
    "        # Fprop\n",
    "        output = model(img)\n",
    "        loss = train_loss(output, img)\n",
    "        # bprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        NEED TEST SET\n",
    "        \n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
