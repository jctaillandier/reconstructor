{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to generate Adult Data and pass it in self.data\n",
    "<ul>\n",
    "    <li> <del>environment virtuel python sur cedar\n",
    "    <li> <del>Make sure GPU is used\n",
    "    <li><del> Need ask best params from Rosin</li>\n",
    "    <li> <del>run Adult\n",
    "    <li> <del> make sure toSave data from PreProcessing somewhere\n",
    "    <li> <del>Wrap to take two csv of corresponding original (label)\n",
    "    <li> <del>Code test testing loop\n",
    "    <li> <del>Same Encoding for labels and training data\n",
    "    <li> Remove Sex attribute from training data\n",
    "    <li> <b>W\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Is dataloaders right shape\n",
    "<li>Writing tensor row by row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *** \n",
      " Currently running on cpu\n",
      " *** \n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/full_original.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acf50245acb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mGET_VALUE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPU_DEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n *** \\n Currently running on {device}\\n *** \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/full_original.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/full_original.csv'"
     ]
    }
   ],
   "source": [
    "# # Imports\n",
    "from Modules import utilities as utils\n",
    "# import datasets as d\n",
    "\n",
    "# from Stats import Plots as Pl\n",
    "import tqdm\n",
    "import time\n",
    "import csv\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import os.path\n",
    "import warnings\n",
    "import importlib\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from torch.utils.data import *\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data as td\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CPU_DEVICE = torch.device(\"cpu\")\n",
    "GET_VALUE = lambda x: x.to(CPU_DEVICE).data.numpy().reshape(-1)[0]\n",
    "print(f\"\\n *** \\n Currently running on {device}\\n *** \\n\")\n",
    "with open('./data/full_original.csv', 'r') as r:\n",
    "        read = csv.reader(r)\n",
    "        header = next(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>162604</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>3</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>91434</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>Private</td>\n",
       "      <td>62611</td>\n",
       "      <td>11th</td>\n",
       "      <td>8</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>221620</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>298102</td>\n",
       "      <td>Masters</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>182136</td>\n",
       "      <td>11th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>126794</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>94214</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>248542</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>337909</td>\n",
       "      <td>11th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>88635</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>77626</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>105721</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>128240</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>123177</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>195904</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>128485</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>42073</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216895</td>\n",
       "      <td>10th</td>\n",
       "      <td>5</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>204121</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>157608</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>174309</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>155168</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>390841</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19</td>\n",
       "      <td>Private</td>\n",
       "      <td>104908</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>129711</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>41</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>127437</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>385832</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>37651</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>102341</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>188801</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>52</td>\n",
       "      <td>Private</td>\n",
       "      <td>58944</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>146025</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>172570</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>39950</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>126035</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>36</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>61997</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>17374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>57</td>\n",
       "      <td>Private</td>\n",
       "      <td>222941</td>\n",
       "      <td>Masters</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>184290</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         workclass  fnlwgt     education  education-num  \\\n",
       "0    53           Private  162604     Bachelors              3   \n",
       "1    23         State-gov   91434  Some-college             10   \n",
       "2    76           Private   62611          11th              8   \n",
       "3    47           Private  221620     Bachelors             13   \n",
       "4    29           Private  298102       Masters              5   \n",
       "5    40           Private  182136          11th              4   \n",
       "6    31           Private  126794     Bachelors             13   \n",
       "7    21           Private   94214  Some-college             10   \n",
       "8    37           Private  248542       HS-grad              9   \n",
       "9    21           Private  337909          11th              8   \n",
       "10   27           Private   88635    Assoc-acdm             12   \n",
       "11   37           Private   77626       HS-grad              9   \n",
       "12   29           Private  105721       HS-grad              9   \n",
       "13   75  Self-emp-not-inc  128240       Masters             14   \n",
       "14   59           Private  123177       HS-grad              9   \n",
       "15   21           Private  195904          11th              7   \n",
       "16   38           Private  128485       HS-grad              9   \n",
       "17   27           Private   42073     Bachelors             13   \n",
       "18   34           Private  216895          10th              5   \n",
       "19   49           Private  204121     Bachelors             13   \n",
       "20   60           Private  157608     Bachelors             13   \n",
       "21   57  Self-emp-not-inc  174309       HS-grad              9   \n",
       "22   46           Private  155168       HS-grad              9   \n",
       "23   36           Private  390841       HS-grad              9   \n",
       "24   19           Private  104908          11th              7   \n",
       "26   47      Self-emp-inc  129711     Bachelors             14   \n",
       "27   41         Local-gov  127437     Bachelors             13   \n",
       "28   44           Private  385832  Some-college             10   \n",
       "29   50  Self-emp-not-inc   37651       HS-grad              7   \n",
       "30   59           Private  102341       HS-grad              7   \n",
       "31   43           Private  188801  Some-college             10   \n",
       "33   52           Private   58944       HS-grad              9   \n",
       "34   30           Private  146025       HS-grad              9   \n",
       "35   37           Private  172570  Some-college             10   \n",
       "36   43           Private   39950     Bachelors             13   \n",
       "37   52  Self-emp-not-inc  126035       HS-grad              9   \n",
       "38   36         State-gov   61997     Bachelors             14   \n",
       "39   37           Private   17374       HS-grad              9   \n",
       "40   57           Private  222941       Masters              6   \n",
       "41   37           Private  184290       HS-grad              9   \n",
       "\n",
       "        marital-status       occupation    relationship   race  sex  \\\n",
       "0        Never-married    Other-service   Not-in-family  White    0   \n",
       "1        Never-married    Other-service       Own-child  White    1   \n",
       "2              Widowed            Sales  Other-relative  White    0   \n",
       "3   Married-civ-spouse  Exec-managerial         Husband  White    1   \n",
       "4   Married-civ-spouse     Craft-repair         Husband  White    1   \n",
       "5   Married-civ-spouse     Craft-repair         Husband  White    1   \n",
       "6   Married-civ-spouse  Exec-managerial         Husband  White    1   \n",
       "7        Never-married    Other-service       Own-child  White    1   \n",
       "8   Married-civ-spouse     Craft-repair         Husband  White    1   \n",
       "9        Never-married     Craft-repair       Own-child  White    1   \n",
       "10       Never-married     Adm-clerical       Own-child  White    1   \n",
       "11  Married-civ-spouse     Adm-clerical         Husband  White    1   \n",
       "12  Married-civ-spouse            Sales         Husband  Black    1   \n",
       "13  Married-civ-spouse  Exec-managerial         Husband  White    1   \n",
       "14       Never-married     Adm-clerical   Not-in-family  Black    1   \n",
       "15       Never-married     Craft-repair       Own-child  White    1   \n",
       "16       Never-married    Other-service   Not-in-family  White    1   \n",
       "17       Never-married            Sales   Not-in-family  White    0   \n",
       "18       Never-married    Other-service  Other-relative  White    1   \n",
       "19  Married-civ-spouse  Exec-managerial         Husband  White    1   \n",
       "20  Married-civ-spouse   Prof-specialty         Husband  White    1   \n",
       "21  Married-civ-spouse            Sales         Husband  White    1   \n",
       "22  Married-civ-spouse   Prof-specialty         Husband  White    1   \n",
       "23  Married-civ-spouse     Craft-repair         Husband  White    1   \n",
       "24       Never-married    Other-service       Own-child  White    1   \n",
       "26  Married-civ-spouse            Sales         Husband  White    1   \n",
       "27            Divorced   Prof-specialty       Unmarried  Black    0   \n",
       "28  Married-civ-spouse     Craft-repair         Husband  White    1   \n",
       "29  Married-civ-spouse     Adm-clerical         Husband  White    1   \n",
       "30       Never-married     Craft-repair   Not-in-family  White    0   \n",
       "31       Never-married            Sales   Not-in-family  White    1   \n",
       "33  Married-civ-spouse            Sales         Husband  White    1   \n",
       "34       Never-married            Sales  Other-relative  White    1   \n",
       "35       Never-married  Exec-managerial   Not-in-family  White    1   \n",
       "36       Never-married    Other-service       Own-child  White    0   \n",
       "37  Married-civ-spouse   Prof-specialty         Husband  White    1   \n",
       "38  Married-civ-spouse   Prof-specialty         Husband  White    1   \n",
       "39            Divorced    Other-service   Not-in-family  White    0   \n",
       "40            Divorced     Craft-repair       Unmarried  White    0   \n",
       "41  Married-civ-spouse    Other-service         Husband  White    1   \n",
       "\n",
       "    capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0              0             0              24  United-States       0  \n",
       "1              0             0              12  United-States       0  \n",
       "2              0             0              23  United-States       0  \n",
       "3              0             0              35      Nicaragua       1  \n",
       "4              0             0              41         Mexico       0  \n",
       "5              0             0              38  United-States       0  \n",
       "6              0             0              38  United-States       0  \n",
       "7              0             0              18  United-States       0  \n",
       "8              0             0              38  United-States       0  \n",
       "9              0             0              20  United-States       0  \n",
       "10             0             0              32  United-States       0  \n",
       "11             0             0              42  United-States       1  \n",
       "12             0             0              38  United-States       0  \n",
       "13             0             0              13  United-States       1  \n",
       "14             0             0              39  United-States       0  \n",
       "15             0             0              32  United-States       0  \n",
       "16             0             0              40  United-States       0  \n",
       "17             0             0              41  United-States       0  \n",
       "18             0             0              31         Mexico       0  \n",
       "19             0             0              43  United-States       1  \n",
       "20             0             0              50  United-States       1  \n",
       "21             0             0              65  United-States       0  \n",
       "22             0             0              31         Mexico       0  \n",
       "23             0             0              42  United-States       0  \n",
       "24             0             0              24  United-States       0  \n",
       "26             0             0              41  United-States       1  \n",
       "27             0             0              38  United-States       0  \n",
       "28             0             0              43  United-States       0  \n",
       "29             0             0              23         Mexico       0  \n",
       "30             0             0              35         Mexico       0  \n",
       "31             0             0              38  United-States       0  \n",
       "33             0             0              46  United-States       0  \n",
       "34             0             0              40  United-States       0  \n",
       "35             0             0              40         Mexico       0  \n",
       "36             0             0              40  United-States       0  \n",
       "37             0             0              94  United-States       0  \n",
       "38             0             0              24  United-States       0  \n",
       "39             0             0              34  United-States       0  \n",
       "40             0             0              33      Nicaragua       0  \n",
       "41             0             0              55  United-States       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>0.668482</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "      <td>0.239282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>0.470764</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "      <td>0.426649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num           sex  capital-gain  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089      0.668482   1079.067626   \n",
       "std       13.710510  1.056040e+05       2.570973      0.470764   7452.019058   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      1.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      1.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000      1.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  48842.000000    48842.000000  48842.000000  \n",
       "mean      87.502314       40.422382      0.239282  \n",
       "std      403.004552       12.391444      0.426649  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     4356.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./data/full_original.csv')\n",
    "b = df2.describe()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  fnlwgt  education-num   sex  capital-gain  capital-loss  \\\n",
       "count   True    True           True  True          True          True   \n",
       "mean   False   False          False  True         False         False   \n",
       "std    False   False          False  True         False         False   \n",
       "min     True    True           True  True          True          True   \n",
       "25%    False   False           True  True          True          True   \n",
       "50%    False   False           True  True          True          True   \n",
       "75%    False   False          False  True          True          True   \n",
       "max     True   False           True  True         False         False   \n",
       "\n",
       "       hours-per-week  income  \n",
       "count            True    True  \n",
       "mean            False    True  \n",
       "std             False    True  \n",
       "min              True    True  \n",
       "25%             False    True  \n",
       "50%             False    True  \n",
       "75%             False    True  \n",
       "max              True    True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_df(tensor: torch.Tensor, headers: List[str]) -> pd.DataFrame:\n",
    "    '''\n",
    "        Takes in a 2d or 3d tensor and its column list and returns datafram\n",
    "        if 3d, we assume first dim (dim=0) is the batch size, hence its ignored\n",
    "\n",
    "\n",
    "    :PARAMS\n",
    "    tensor: tensor to convert\n",
    "    headers: list of headers to assign in that order. Must be same size \n",
    "                as last dim of tensor parameter.\n",
    "\n",
    "    '''\n",
    "    if tensor.shape[-1] != len(headers):\n",
    "        raise ValueError(f\"Tensor's last dimension ({tensor.shape[-1]}) must match headers length ({len(headers)})\")\n",
    "\n",
    "    df = pd.DataFrame (tensor.tolist(), columns=headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [5, 1], [9, 1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[2,3],[5,1],[9,1]])\n",
    "head = ['abbb','bcccc']\n",
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbb</th>\n",
       "      <th>bcccc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbb  bcccc\n",
       "0     2      3\n",
       "1     5      1\n",
       "2     9      1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_to_df(a, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = 'manual_test'\n",
    "# path_to_exp = utils.check_dir_path(f'./experiments/{exp_name}/')\n",
    "# os.mkdir(path_to_exp)\n",
    "# Data import & Pre-processing\n",
    "  \n",
    "class My_dataLoader:\n",
    "    def __init__(self, batch_size : int, data_path :str, label_path:str, n_train :int,  label_col_name:str, test_batch_size:int=128):\n",
    "        '''\n",
    "            Creates train and test loaders from local files, to be easily used by torch.nn\n",
    "            \n",
    "            :batch_size: int for size of training batches\n",
    "            :data_path: path to csv where data is. 2d file\n",
    "            :label_path: csv containing labels. line by line equivalent to data_path file\n",
    "            :n_train: int for the size of training set (assigned randomly)\n",
    "            :test_batch: size of batches at test time. If none, will be same \n",
    "                    as training\n",
    "            :label_col_name name of columns that contains labels\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = n_train\n",
    "        \n",
    "        df_data = pd.read_csv(data_path)\n",
    "        df_label = pd.read_csv(label_path)\n",
    "        \n",
    "        a = df_data.values\n",
    "        b = df_label.values\n",
    "        self.trdata = torch.tensor(a[:self.train_size,:]) # where data is 2d [D_train_size x features]\n",
    "        self.trlabels = torch.tensor(b[:self.train_size,:]) # also has too be 2d\n",
    "        self.tedata = torch.tensor(a[self.train_size:,:]) # where data is 2d [D_train_size x features]\n",
    "        self.telabels = torch.tensor(b[self.train_size:,:]) # also has too be 2d\n",
    "        \n",
    "        self.train_dataset = torch.utils.data.TensorDataset(self.trdata, self.trlabels)\n",
    "        self.test_dataset = torch.utils.data.TensorDataset(self.tedata, self.telabels)\n",
    "\n",
    "        # Split dataset into train and Test sets\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        if test_batch_size == 'full':\n",
    "            test_batch_size = len(self.test_dataset)\n",
    "            \n",
    "        self.test_loader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=test_batch_size,\n",
    "            num_workers=1,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "class PreProcessing:\n",
    "    def __init__(self, params_file: str):\n",
    "        '''\n",
    "            Imports all variables/parameters necessary for preparation of training.\n",
    "            Looks into params.yaml, then creates dataloader that can be used\n",
    "            \n",
    "            params_file: path to file that contains parameters.\n",
    "                            Needs to follow a specific naming and format\n",
    "        '''\n",
    "        \n",
    "        # Import params\n",
    "        stream = open(params_file, 'r')\n",
    "        self.params = yaml.load(stream, yaml.FullLoader)\n",
    "\n",
    "        import_path = self.params['data_loading']['data_path']['value']\n",
    "        label_path = self.params['data_loading']['label_path']['value']\n",
    "\n",
    "        batchSize = self.params['model_params']['batchSize']['value']        \n",
    "        test_batch_size = self.params['model_params']['test_batch_size']['value']        \n",
    "        percent_train_set = self.params['model_params']['percent_train_set']['value']\n",
    "        \n",
    "        #Make encoding object to transform categorical\n",
    "        self.data_pp = utils.encode(import_path)\n",
    "        self.labels_pp = utils.encode(label_path)\n",
    "        print(f\"Saving output dataset under {import_path[:-4]}_NoCat.csv \\n\")\n",
    "        self.data_pp.df.to_csv(f\"{import_path[:-4]}_NoCat.csv\", index=False)\n",
    "        self.labels_pp.df.to_csv(f\"{label_path[:-4]}_NoCat.csv\", index=False)\n",
    "\n",
    "        # MAke sure post processing label and data are of same shape\n",
    "        if self.data_pp.df.shape != self.data_pp.df.shape:\n",
    "            print(self.df_data.shape)\n",
    "            print(self.df_labels.shape)\n",
    "            raise ValueError(\"The labels csv and data post-encoding don't have the same shape.\")\n",
    "\n",
    "        self.dataloader = My_dataLoader(batchSize, f\"{import_path[:-4]}_NoCat.csv\", f\"{label_path[:-4]}_NoCat.csv\", n_test, \"income\", test_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.Sigmoid(), nn.Linear(8, 4))#, nn.ReLU(True), nn.Linear(4, 4))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.25),\n",
    "#             nn.Linear(10, 16),\n",
    "#             nn.ReLU(True),\n",
    "            nn.Linear(16, 24),\n",
    "            nn.Sigmoid(), nn.Linear(24, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "def train(model,train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "      \n",
    "        #inputs = inputs.view(batchSize, 1,100,100)\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs.float())\n",
    "        loss = loss_fn(output.float(), target.float())\n",
    "        train_loss.append(loss)\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = sum(train_loss) / batch_idx+1\n",
    "    return mean_loss\n",
    "\n",
    "def test(model, test_loader, test_loss_fn, last_epoch=False):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_size = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            \n",
    "            if last_epoch == True:\n",
    "                data = inputs.tolist()\n",
    "                with open(f\"./experiments/{str.replace(time.ctime()[4:-8], ' ', '_')}-original_testset.csv\", 'w', newline=\"\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(header)\n",
    "                    writer.writerows(data)\n",
    "                \n",
    "            output = model(inputs.float())\n",
    "\n",
    "            if last_epoch == True:\n",
    "                data = output.tolist()\n",
    "                with open(f\"./experiments/{str.replace(time.ctime()[4:-8], ' ', '_')}-generated_testset.csv\", 'w', newline=\"\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(header)\n",
    "                    writer.writerows(data)\n",
    "            \n",
    "            test_size += len(inputs.float())\n",
    "            test_loss += test_loss_fn(output.float(), target.float()).item() \n",
    "    test_loss /= test_size\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Autoencoder(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'batchSize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3e337677096a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training on {num_epochs} epochs completed in {(end-start)/60} minutes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"params.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# train_model(experiment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-54684c88fbf9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params_file)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_loading'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mbatchSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batchSize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpercent_train_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_train_set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'batchSize'"
     ]
    }
   ],
   "source": [
    "def train_model(experiment_x: PreProcessing, model_type:str='autoencoder'):\n",
    "    '''\n",
    "        Takes care of all model training, testing and generation of data\n",
    "        \n",
    "        experiment_x: PreProcessing object that contains all data and parameters\n",
    "    \n",
    "    '''\n",
    "    start = time.time()\n",
    "    wd = experiment_x.params['model_params']['weight_decay']['value']\n",
    "    learning_rate = experiment_x.params['model_params']['learning_rate']['value']\n",
    "\n",
    "    num_epochs = int(experiment_x.params['model_params']['num_epochs']['value'])\n",
    "\n",
    "    in_dim = experiment_x.dataloader.trdata.shape[1]\n",
    "    out_dim = experiment_x.dataloader.trlabels.shape[1]\n",
    "    #######\n",
    "\n",
    "    if model_type == 'autoencoder':\n",
    "        model = Autoencoder(in_dim, out_dim).to(device)\n",
    "    train_loss = torch.nn.L1Loss().to(device) # BCEWithLogitsLoss combines sig, so no need activate out layer with softmax\n",
    "    test_loss_fn =torch.nn.L1Loss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "    test_accuracy = []\n",
    "    ave_train_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch} running...\")\n",
    "\n",
    "        batch_ave_tr_loss = train(model,experiment_x.dataloader.train_loader, optimizer, train_loss)\n",
    "        ave_train_loss.append(batch_ave_tr_loss)\n",
    "\n",
    "        last = False\n",
    "        if epoch+1 == num_epochs: # then save the test batch input and output for metrics\n",
    "            last = True\n",
    "        loss = test(model, experiment_x.dataloader.test_loader, test_loss_fn, last)\n",
    "\n",
    "        print(f\"Epoch {epoch} complete. Test Loss: {loss:.4f} \\n\")      \n",
    "        test_accuracy.append(loss)\n",
    "\n",
    "\n",
    "    a = experiment_x.params['data_loading']['data_path']['value'][36:].split('/')[0]\n",
    "\n",
    "    fm = open(f\"./experiments/{str.replace(time.ctime(), ' ', '_')}-{a}.pth\", \"wb\")\n",
    "    torch.save(model.state_dict(), fm)\n",
    "\n",
    "    with open(f\"./experiments/{str.replace(time.ctime(), ' ', '_')}-{a}.txt\", 'w+') as f:\n",
    "        f.write(f\"Epochs: {num_epochs} \\n\")\n",
    "        f.write(f\"Learning Rate: {learning_rate} \\n\")\n",
    "        f.write(f\"weight decay: {wd}\\n\")\n",
    "        f.write(f\"Training Loss: {str(train_loss)}\\n\")\n",
    "        f.write(f\"Test Loss: {str(test_loss_fn)} \\n\")\n",
    "        f.write(f\"Optimizer: {str(optimizer)}\\n\")\n",
    "        f.write(f\"Train loss values: {str(ave_train_loss)} \\n\")\n",
    "        f.write(f\"Test loss values: {str(test_accuracy)}\\n\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Training on {num_epochs} epochs completed in {(end-start)/60} minutes.\")\n",
    "    \n",
    "experiment = PreProcessing(\"params.yaml\")\n",
    "\n",
    "# train_model(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ef14ac349c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-ef14ac349c3f>\u001b[0m in \u001b[0;36mfrom_dummies\u001b[0;34m(data, categories, prefix_sep)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     data = self.df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     categories = self.cat_clm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcat_was_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtype' is not defined"
     ]
    }
   ],
   "source": [
    "def from_dummies(data, categories, prefix_sep='-'):\n",
    "    \"\"\"\n",
    "        Convert encoded columns into original ones\n",
    "    \"\"\"\n",
    "#     data = self.df\n",
    "#     categories = self.cat_clm\n",
    "    cat_was_num = {'sex': dtype('int64'), 'income': dtype('int64')}\n",
    "    out = data.copy()\n",
    "    for l in categories:\n",
    "        cols = data.filter(regex=\"^{}{}\".format(l, prefix_sep), axis=1).columns\n",
    "        labs = [cols[i].split(prefix_sep)[-1] for i in range(cols.shape[0])]\n",
    "        import pdb;pdb.set_trace()\n",
    "        out[l] = pd.Categorical(np.array(labs)[np.argmax(data[cols].values, axis=1)])\n",
    "        out.drop(cols, axis=1, inplace=True)\n",
    "        if l in cat_was_num.keys():\n",
    "            out[l] = out[l].astype(cat_was_num[l])\n",
    "\n",
    "    return out\n",
    "\n",
    "a = from_dummies(df, unique_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Modules import datasets as d\n",
    "\n",
    "prm_file = \"/home/jc/Desktop/udem_H20/thesis_research/gansan/Experiments/AdultTotalC/Exp_1/Prm/\"\n",
    "path_to_exp = \"/home/jc/Desktop/udem_H20/thesis_research/reconstructor/experiments/manual_test/\"\n",
    "\n",
    "d_i = d.Preprocessing('/home/jc/Desktop/udem_H20/thesis_research/reconstructor/data/full_original.csv')\n",
    "d_i.load_parameters(prmPath=prm_file)\n",
    "d_i.transform()\n",
    "d_i.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>sex=0</th>\n",
       "      <th>sex=1</th>\n",
       "      <th>income=0</th>\n",
       "      <th>income=1</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country=Portugal</th>\n",
       "      <th>native-country=Puerto-Rico</th>\n",
       "      <th>native-country=Scotland</th>\n",
       "      <th>native-country=South</th>\n",
       "      <th>native-country=Taiwan</th>\n",
       "      <th>native-country=Thailand</th>\n",
       "      <th>native-country=Trinadad&amp;Tobago</th>\n",
       "      <th>native-country=United-States</th>\n",
       "      <th>native-country=Vietnam</th>\n",
       "      <th>native-country=Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.157823</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.048121</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.090175</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.145665</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.130317</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.249141</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.118744</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows  110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0      0.342466  0.157823       0.800000      0.000000           0.0   \n",
       "1      0.493151  0.093023       0.800000      0.076881           0.0   \n",
       "2      0.205479  0.048121       0.800000      0.000000           0.0   \n",
       "3      0.575342  0.090175       0.666667      0.000000           0.0   \n",
       "4      0.041096  0.145665       0.533333      0.000000           0.0   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "48837  0.602740  0.130317       0.400000      0.000000           0.0   \n",
       "48838  0.082192  0.249141       0.600000      0.000000           0.0   \n",
       "48839  0.328767  0.118744       0.600000      0.000000           0.0   \n",
       "48840  0.328767  0.115632       0.533333      0.000000           0.0   \n",
       "48841  0.000000  0.015775       0.466667      0.000000           0.0   \n",
       "\n",
       "       hours-per-week  sex=0  sex=1  income=0  income=1  ...  \\\n",
       "0            0.112245    1.0    0.0       1.0       0.0  ...   \n",
       "1            0.397959    0.0    1.0       0.0       1.0  ...   \n",
       "2            0.346939    0.0    1.0       0.0       1.0  ...   \n",
       "3            0.397959    0.0    1.0       0.0       1.0  ...   \n",
       "4            0.397959    1.0    0.0       1.0       0.0  ...   \n",
       "...               ...    ...    ...       ...       ...  ...   \n",
       "48837        0.357143    0.0    1.0       1.0       0.0  ...   \n",
       "48838        0.397959    0.0    1.0       0.0       1.0  ...   \n",
       "48839        0.397959    0.0    1.0       1.0       0.0  ...   \n",
       "48840        0.500000    0.0    1.0       0.0       1.0  ...   \n",
       "48841        0.193878    1.0    0.0       1.0       0.0  ...   \n",
       "\n",
       "       native-country=Portugal  native-country=Puerto-Rico  \\\n",
       "0                          0.0                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          0.0                         0.0   \n",
       "3                          0.0                         0.0   \n",
       "4                          0.0                         0.0   \n",
       "...                        ...                         ...   \n",
       "48837                      0.0                         0.0   \n",
       "48838                      0.0                         0.0   \n",
       "48839                      0.0                         0.0   \n",
       "48840                      0.0                         0.0   \n",
       "48841                      0.0                         0.0   \n",
       "\n",
       "       native-country=Scotland  native-country=South  native-country=Taiwan  \\\n",
       "0                          0.0                   0.0                    0.0   \n",
       "1                          0.0                   0.0                    0.0   \n",
       "2                          0.0                   0.0                    0.0   \n",
       "3                          0.0                   0.0                    0.0   \n",
       "4                          0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "48837                      0.0                   0.0                    0.0   \n",
       "48838                      0.0                   0.0                    0.0   \n",
       "48839                      0.0                   0.0                    0.0   \n",
       "48840                      0.0                   0.0                    0.0   \n",
       "48841                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native-country=Thailand  native-country=Trinadad&Tobago  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "2                          0.0                             0.0   \n",
       "3                          0.0                             0.0   \n",
       "4                          0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "48837                      0.0                             0.0   \n",
       "48838                      0.0                             0.0   \n",
       "48839                      0.0                             0.0   \n",
       "48840                      0.0                             0.0   \n",
       "48841                      0.0                             0.0   \n",
       "\n",
       "       native-country=United-States  native-country=Vietnam  \\\n",
       "0                               0.0                     0.0   \n",
       "1                               1.0                     0.0   \n",
       "2                               1.0                     0.0   \n",
       "3                               1.0                     0.0   \n",
       "4                               1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "48837                           1.0                     0.0   \n",
       "48838                           1.0                     0.0   \n",
       "48839                           1.0                     0.0   \n",
       "48840                           1.0                     0.0   \n",
       "48841                           1.0                     0.0   \n",
       "\n",
       "       native-country=Yugoslavia  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "48837                        0.0  \n",
       "48838                        0.0  \n",
       "48839                        0.0  \n",
       "48840                        0.0  \n",
       "48841                        0.0  \n",
       "\n",
       "[48842 rows x 110 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,num_epochs+1), np.array(test_accuracy))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"L1 Loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.savefig(f\"./experiments/{str.replace(time.ctime(), ' ', '_')}-{a}_test-loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-72b20c4aec5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L1 Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss - average per epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./experiments/{str.replace(time.ctime(), ' ', '_')}-{a}_train-loss.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(1,num_epochs+1), np.array(train_losses))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"L1 Loss\")\n",
    "plt.title(\"Train Loss - average per epoch\")\n",
    "plt.savefig(f\"./experiments/{str.replace(time.ctime(), ' ', '_')}-{a}_train-loss.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
