from typing import List
from Modules import datasets as d
from Modules import analysisTools as at
import pandas as pd
import os
import torch
import argparse


    
def encode(data_path: str)-> d.Encoder:
    '''
        Encodes the same way gansan does. It returns an object that contains the meta data
        about the encoding and will be need to call decode() and retrieve original columns
        
        :PARAMS
        data_path: Path to the original data to be encoded, and where .prm is situated
        
        return: d.Preprocessing obj; obj.df returns data in dataframe, 
                                        obj.inverse_transform() to reverse encoding
    '''

    d_i = d.Encoder(data_path)
    d_i.load_parameters(prmPath='./data/')
    d_i.transform()
    
    return d_i
    

def check_dir_path(path_to_check: str) -> str:
    '''
        Checks if provided path is currently a at current level directory.
        If it is, it appends a number to the end and checks again 
        until no directory with such name exists

        :PARAMS
        path_to_check: str The path to location to check

        return: str New path with which os.mkdir can be called
    '''
    new_path = path_to_check
    if os.path.isdir(path_to_check):
        print("Experiment with name: \'{}\' already exists. Appending int to folder name. ".format(path_to_check))
        if os.path.isdir(path_to_check):
            expand = 1
            while True:
                expand += 1
                new_path = path_to_check[:-1] + '_' + str(expand) + '/'
                if os.path.isdir(new_path):
                    continue
                else:
                    break
            print(f"Experiment path: {new_path} \n \n ")
    return new_path

def parse_arguments(parser):
    parser.add_argument('--batch_size', type=int, default=128, help='The dimension size of the embedding, which will be generated by the generator. (default value: 128)')

    parser.add_argument('--generate_data', type=str2bool, default=False, help='If True the model generates data, if False the model is trained (default value: False)')

    args = parser.parse_args()
    return args

def tensor_to_df(tensor: torch.Tensor, headers: List[str]) -> pd.DataFrame:
    '''
        Takes in a 2d or 3d tensor and its column list and returns datafram
        if 3d, we assume first dim (dim=0) is the batch size, hence its ignored


    :PARAMS
    tensor: tensor to convert
    headers: list of headers to assign in that order. Must be same size 
                as last dim of tensor parameter.

    '''
    if tensor.shape[-1] != len(headers):
        raise ValueError(f"Tensor's last dimension ({tensor.shape[-1]}) must match headers length ({len(headers)})")

    
    return pd.DataFrame (tensor.tolist(), columns=headers)
