Epochs: 250 
 
Total of 10 / 82 are now closer to original data (L1 distance). 
 
Lowest lost Generated:
 [0.03309030085802078, 0.03958064317703247, 0.04492177441716194, 0.1568659245967865, 0.18371987342834473, 0.033860959112644196, 0.021501390263438225, 0.029448416084051132, 0.021065788343548775, 0.01658245362341404, 0.03259013220667839, 0.019556695595383644, 0.05435406044125557, 0.014007742516696453, 0.017782609909772873, 0.04924154654145241, 0.03166786581277847, 0.03778683766722679, 0.016255194321274757, 0.009270680136978626, 0.01699676923453808, 0.03587048128247261, 0.05141006410121918, 0.0428171306848526, 0.021330129355192184, 0.05710488557815552, 0.0063906339928507805, 0.01940676011145115, 0.02870223857462406, 0.018503235653042793, 0.023676006123423576, 0.014876934699714184, 0.014732647687196732, 0.03407241776585579, 0.013398886658251286, 0.048318251967430115, 0.0024549695663154125, 0.03068290278315544, 0.04884357377886772, 0.03213435411453247, 0.05272954702377319, 0.06614432483911514, 0.03320377320051193, 0.010176951065659523, 0.03519853204488754, 0.12053869664669037, 0.03323601186275482, 0.026313085108995438, 0.019022729247808456, 0.013301622122526169, 0.03096483089029789, 0.010762008838355541, 0.014751271344721317, 0.013016796670854092, 0.010957545600831509, 0.019987117499113083, 0.014940942637622356, 0.028549324721097946, 0.003896167501807213, 0.008186698891222477, 0.005226674489676952, 0.0054880413226783276, 0.0062434617429971695, 0.007989326491951942, 0.013050122186541557, 0.005555302836000919, 0.006201763637363911, 0.005140089429914951, 0.003396685468032956, 0.0038999058306217194, 0.003859864082187414, 0.0048323688097298145, 0.01901451125741005, 0.004381054081022739, 0.006141775753349066, 0.005741812288761139, 0.004525990225374699, 0.00756038585677743, 0.004837485961616039, 0.0041300589218735695, 0.005013310816138983, 0.04879147559404373] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 5e-06 
Number Epochs: 250 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 45.24 minutes
Train loss values: [127.41683959960938, 96.33108520507812, 88.69312286376953, 80.04357147216797, 74.63150024414062, 70.83686065673828, 66.50868225097656, 62.765201568603516, 60.23628616333008, 58.00484085083008, 55.5703125, 53.42632293701172, 52.03580093383789, 51.20661926269531, 49.926700592041016, 49.42200469970703, 48.631744384765625, 47.87660598754883, 47.01481246948242, 46.39712142944336, 45.60969543457031, 44.82038879394531, 44.30994415283203, 44.143272399902344, 43.56305694580078, 43.14055252075195, 43.01451873779297, 42.507789611816406, 42.01431655883789, 41.22198486328125, 41.00834655761719, 40.46455383300781, 39.9658317565918, 39.54051971435547, 39.07194900512695, 38.81010437011719, 38.460906982421875, 38.3057746887207, 38.26088333129883, 38.732242584228516, 38.55009460449219, 38.23160934448242, 38.0892448425293, 37.49064636230469, 37.43864059448242, 37.18754196166992, 36.94259262084961, 36.74061965942383, 36.941925048828125, 36.89666748046875, 36.672054290771484, 36.24336242675781, 35.79909133911133, 35.88100051879883, 36.541053771972656, 36.77682876586914, 36.54411315917969, 35.9986686706543, 35.50054931640625, 35.308406829833984, 35.100685119628906, 35.21815872192383, 35.4147834777832, 35.192626953125, 35.181884765625, 35.36118698120117, 34.63011169433594, 33.90647506713867, 33.878292083740234, 33.82404327392578, 33.8085823059082, 34.254371643066406, 34.45308303833008, 34.152320861816406, 33.89577102661133, 34.35322952270508, 34.57569122314453, 34.61965560913086, 34.02898406982422, 33.708763122558594, 33.57753372192383, 33.89043045043945, 33.956661224365234, 33.91778564453125, 33.95905303955078, 34.0582160949707, 34.02195358276367, 33.367523193359375, 32.85576248168945, 32.35834884643555, 31.992427825927734, 32.092384338378906, 32.14663314819336, 32.1984977722168, 32.19913101196289, 32.493370056152344, 32.47127914428711, 32.60927200317383, 32.63777160644531, 32.47511291503906, 32.10969543457031, 32.57527160644531, 32.46830749511719, 32.39064025878906, 32.1531867980957, 32.49750900268555, 32.534664154052734, 33.05260467529297, 32.89380645751953, 32.21907043457031, 31.685070037841797, 31.563735961914062, 31.64794921875, 31.878995895385742, 32.75581359863281, 32.851619720458984, 32.33639144897461, 32.180843353271484, 32.50889205932617, 32.9317512512207, 32.85675048828125, 32.49025344848633, 32.47220230102539, 31.67607307434082, 31.577043533325195, 31.994123458862305, 31.4998836517334, 31.393917083740234, 32.99174880981445, 32.40118408203125, 32.604408264160156, 33.31840896606445, 32.43135452270508, 31.196767807006836, 31.052400588989258, 31.668630599975586, 31.864831924438477, 31.8089542388916, 32.014007568359375, 31.421470642089844, 31.853240966796875, 32.69268035888672, 32.278709411621094, 31.622617721557617, 31.15890884399414, 30.99538230895996, 31.872148513793945, 32.11250686645508, 31.929183959960938, 32.4599494934082, 32.183509826660156, 32.075462341308594, 32.05070495605469, 32.25263214111328, 32.311527252197266, 32.704654693603516, 32.50122833251953, 32.59405517578125, 31.24562644958496, 30.91398811340332, 30.60121726989746, 30.333805084228516, 30.832624435424805, 30.921667098999023, 31.322465896606445, 31.92804718017578, 31.43634796142578, 30.749526977539062, 30.4708251953125, 30.651426315307617, 31.593107223510742, 31.78473663330078, 31.5039005279541, 31.01531219482422, 30.584869384765625, 30.84401512145996, 30.727550506591797, 30.759977340698242, 30.122961044311523, 30.029293060302734, 29.594470977783203, 29.406982421875, 29.993133544921875, 30.543670654296875, 30.603113174438477, 30.88754653930664, 30.745372772216797, 30.671428680419922, 30.643898010253906, 30.349103927612305, 30.192848205566406, 30.356536865234375, 30.337875366210938, 30.470794677734375, 30.088287353515625, 29.706451416015625, 29.378629684448242, 29.10280990600586, 29.48154640197754, 30.0194091796875, 30.154380798339844, 31.289226531982422, 30.87856101989746, 31.068002700805664, 30.089426040649414, 29.975181579589844, 29.381919860839844, 30.601818084716797, 30.489612579345703, 31.040178298950195, 30.940704345703125, 30.031770706176758, 29.227949142456055, 28.610342025756836, 28.778167724609375, 30.7103328704834, 31.1483097076416, 30.643489837646484, 30.005950927734375, 30.266292572021484, 30.00722885131836, 30.998865127563477, 31.750749588012695, 31.365171432495117, 30.522035598754883, 29.897811889648438, 29.824228286743164, 29.340126037597656, 29.61587142944336, 29.34604835510254, 30.146018981933594, 30.712013244628906, 30.129337310791016, 29.95151138305664, 29.618127822875977, 31.284841537475586, 32.32632827758789, 31.103389739990234, 30.87921905517578, 30.25080108642578, 30.006237030029297, 30.1680908203125, 30.432273864746094, 30.364856719970703, 30.478919982910156, 29.591285705566406, 29.479047775268555, 29.58115577697754, 29.2465877532959, 29.95246124267578] 
Test loss values: [tensor(0.1004), tensor(0.0876), tensor(0.0812), tensor(0.0723), tensor(0.0695), tensor(0.0653), tensor(0.0612), tensor(0.0582), tensor(0.0560), tensor(0.0538), tensor(0.0511), tensor(0.0504), tensor(0.0488), tensor(0.0471), tensor(0.0477), tensor(0.0452), tensor(0.0465), tensor(0.0439), tensor(0.0439), tensor(0.0436), tensor(0.0425), tensor(0.0421), tensor(0.0421), tensor(0.0412), tensor(0.0412), tensor(0.0408), tensor(0.0406), tensor(0.0401), tensor(0.0388), tensor(0.0388), tensor(0.0380), tensor(0.0378), tensor(0.0375), tensor(0.0366), tensor(0.0369), tensor(0.0360), tensor(0.0361), tensor(0.0352), tensor(0.0365), tensor(0.0360), tensor(0.0369), tensor(0.0365), tensor(0.0351), tensor(0.0351), tensor(0.0348), tensor(0.0349), tensor(0.0344), tensor(0.0339), tensor(0.0347), tensor(0.0352), tensor(0.0343), tensor(0.0339), tensor(0.0336), tensor(0.0331), tensor(0.0341), tensor(0.0344), tensor(0.0330), tensor(0.0337), tensor(0.0341), tensor(0.0333), tensor(0.0320), tensor(0.0339), tensor(0.0338), tensor(0.0335), tensor(0.0335), tensor(0.0333), tensor(0.0321), tensor(0.0319), tensor(0.0322), tensor(0.0315), tensor(0.0329), tensor(0.0328), tensor(0.0326), tensor(0.0316), tensor(0.0321), tensor(0.0326), tensor(0.0326), tensor(0.0319), tensor(0.0309), tensor(0.0318), tensor(0.0318), tensor(0.0319), tensor(0.0328), tensor(0.0308), tensor(0.0316), tensor(0.0324), tensor(0.0319), tensor(0.0312), tensor(0.0304), tensor(0.0298), tensor(0.0303), tensor(0.0308), tensor(0.0307), tensor(0.0303), tensor(0.0306), tensor(0.0297), tensor(0.0311), tensor(0.0307), tensor(0.0313), tensor(0.0305), tensor(0.0315), tensor(0.0305), tensor(0.0301), tensor(0.0295), tensor(0.0297), tensor(0.0302), tensor(0.0305), tensor(0.0301), tensor(0.0308), tensor(0.0308), tensor(0.0292), tensor(0.0299), tensor(0.0297), tensor(0.0315), tensor(0.0302), tensor(0.0295), tensor(0.0305), tensor(0.0305), tensor(0.0311), tensor(0.0311), tensor(0.0301), tensor(0.0314), tensor(0.0300), tensor(0.0306), tensor(0.0298), tensor(0.0296), tensor(0.0297), tensor(0.0312), tensor(0.0295), tensor(0.0315), tensor(0.0331), tensor(0.0322), tensor(0.0305), tensor(0.0295), tensor(0.0303), tensor(0.0290), tensor(0.0296), tensor(0.0312), tensor(0.0293), tensor(0.0296), tensor(0.0308), tensor(0.0287), tensor(0.0308), tensor(0.0287), tensor(0.0287), tensor(0.0307), tensor(0.0289), tensor(0.0292), tensor(0.0290), tensor(0.0304), tensor(0.0299), tensor(0.0307), tensor(0.0322), tensor(0.0308), tensor(0.0309), tensor(0.0316), tensor(0.0308), tensor(0.0304), tensor(0.0306), tensor(0.0293), tensor(0.0276), tensor(0.0297), tensor(0.0290), tensor(0.0311), tensor(0.0286), tensor(0.0309), tensor(0.0300), tensor(0.0286), tensor(0.0290), tensor(0.0309), tensor(0.0296), tensor(0.0290), tensor(0.0295), tensor(0.0286), tensor(0.0287), tensor(0.0289), tensor(0.0295), tensor(0.0292), tensor(0.0280), tensor(0.0279), tensor(0.0279), tensor(0.0283), tensor(0.0270), tensor(0.0286), tensor(0.0285), tensor(0.0284), tensor(0.0297), tensor(0.0287), tensor(0.0290), tensor(0.0271), tensor(0.0272), tensor(0.0296), tensor(0.0291), tensor(0.0283), tensor(0.0277), tensor(0.0276), tensor(0.0266), tensor(0.0265), tensor(0.0291), tensor(0.0296), tensor(0.0300), tensor(0.0274), tensor(0.0298), tensor(0.0293), tensor(0.0288), tensor(0.0268), tensor(0.0297), tensor(0.0271), tensor(0.0282), tensor(0.0296), tensor(0.0283), tensor(0.0277), tensor(0.0269), tensor(0.0266), tensor(0.0287), tensor(0.0269), tensor(0.0286), tensor(0.0278), tensor(0.0285), tensor(0.0295), tensor(0.0296), tensor(0.0305), tensor(0.0296), tensor(0.0282), tensor(0.0269), tensor(0.0279), tensor(0.0265), tensor(0.0267), tensor(0.0276), tensor(0.0273), tensor(0.0297), tensor(0.0280), tensor(0.0293), tensor(0.0282), tensor(0.0294), tensor(0.0301), tensor(0.0296), tensor(0.0296), tensor(0.0283), tensor(0.0290), tensor(0.0280), tensor(0.0278), tensor(0.0287), tensor(0.0297), tensor(0.0283), tensor(0.0280), tensor(0.0282), tensor(0.0282), tensor(0.0283), tensor(0.0289)]
