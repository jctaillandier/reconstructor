Epochs: 250 
 
Total of 4 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 5 
 
Average lowest loss: 0.075023247905802435 
 
Lowest lost Generated:
 [0.1577584147453308, 0.1132366955280304, 0.15298520028591156, 0.16143713891506195, 0.18700146675109863, 0.1162860095500946, 0.12976323068141937, 0.17378400266170502, 0.17217354476451874, 0.08581829071044922, 0.040223896503448486, 0.07737146317958832, 0.31495076417922974, 0.043831732124090195, 0.0927063599228859, 0.051583584398031235, 0.035400714725255966, 0.04113851115107536, 0.01762726902961731, 0.013523774221539497, 0.018073881044983864, 0.03985295817255974, 0.05222899094223976, 0.18619757890701294, 0.3373848497867584, 0.061371199786663055, 0.007664732169359922, 0.019237862899899483, 0.220719113945961, 0.1486511528491974, 0.11212671548128128, 0.02171640656888485, 0.12663555145263672, 0.03877123445272446, 0.03816461190581322, 0.13208365440368652, 0.00669574411585927, 0.14446181058883667, 0.13688994944095612, 0.041354261338710785, 0.053621843457221985, 0.07141368091106415, 0.12277393788099289, 0.018046267330646515, 0.14525756239891052, 0.13234908878803253, 0.0361650325357914, 0.09821809083223343, 0.25800544023513794, 0.038829416036605835, 0.1609644591808319, 0.10655894875526428, 0.055089071393013, 0.017380373552441597, 0.04074351489543915, 0.09869719296693802, 0.015359851531684399, 0.20781631767749786, 0.006331541575491428, 0.01258885208517313, 0.010730304755270481, 0.006129510700702667, 0.012582693248987198, 0.013924322091042995, 0.01224298495799303, 0.011630512773990631, 0.009571979753673077, 0.01023156475275755, 0.013238463550806046, 0.00812734104692936, 0.0059866150841116905, 0.005438635591417551, 0.02968773804605007, 0.01495812926441431, 0.007546892389655113, 0.011581873521208763, 0.008943653665482998, 0.016206812113523483, 0.007978606037795544, 0.005272807087749243, 0.010087238624691963, 0.15471284091472626] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 0.0001 
Number Epochs: 250 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 15.91 minutes
