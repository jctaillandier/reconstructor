Epochs: 1200 
 
Total of 8 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 626 
 
Average lowest loss: 0.026101579827188356626 
 
Lowest lost Generated:
 [0.028537146747112274, 0.0406663678586483, 0.03750133886933327, 0.16099928319454193, 0.18696248531341553, 0.04947739839553833, 0.026569094508886337, 0.024538373574614525, 0.021207382902503014, 0.017062485218048096, 0.012979350052773952, 0.018172523006796837, 0.034264493733644485, 0.015294602140784264, 0.017230307683348656, 0.017577575519680977, 0.03488563746213913, 0.04575413465499878, 0.018044104799628258, 0.011980745010077953, 0.022055484354496002, 0.040622562170028687, 0.03830675780773163, 0.04140607267618179, 0.02320501022040844, 0.01963825710117817, 0.008477154187858105, 0.023313866928219795, 0.024378255009651184, 0.023907039314508438, 0.03166282922029495, 0.018931642174720764, 0.020476344972848892, 0.018165957182645798, 0.011920573189854622, 0.02889230102300644, 0.0068700844421982765, 0.026138663291931152, 0.037086986005306244, 0.03806459158658981, 0.053704433143138885, 0.06991937756538391, 0.024381335824728012, 0.012963930144906044, 0.0316983163356781, 0.09968588501214981, 0.041283804923295975, 0.024769466370344162, 0.03157934918999672, 0.013730197213590145, 0.017271170392632484, 0.023938337340950966, 0.01658768393099308, 0.017787864431738853, 0.017587443813681602, 0.021236415952444077, 0.013559608720242977, 0.02498907595872879, 0.007453916594386101, 0.0118520213291049, 0.009719557128846645, 0.011197988875210285, 0.010324143804609776, 0.009415291249752045, 0.013424351811408997, 0.009627582505345345, 0.007436643820255995, 0.01040907483547926, 0.007874680683016777, 0.00801814068108797, 0.0060223862528800964, 0.00890956912189722, 0.021502036601305008, 0.008685936219990253, 0.005669058300554752, 0.009471696801483631, 0.008425015024840832, 0.0106732789427042, 0.006869135424494743, 0.008356891572475433, 0.009786374866962433, 0.03930581361055374] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 923.31 minutes
