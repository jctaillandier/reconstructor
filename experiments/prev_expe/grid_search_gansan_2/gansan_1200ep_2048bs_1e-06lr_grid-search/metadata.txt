Epochs: 1200 
 
Total of 13 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 1149 
 
Average lowest loss: 0.0285245852584655321149 
 
Lowest lost Generated:
 [0.0321180559694767, 0.03709740564227104, 0.037513963878154755, 0.15952584147453308, 0.1807819902896881, 0.028537731617689133, 0.01984293945133686, 0.021631844341754913, 0.02363654598593712, 0.021451817825436592, 0.03670124337077141, 0.01870996691286564, 0.0649225190281868, 0.01653527468442917, 0.021811744198203087, 0.05137476325035095, 0.031890884041786194, 0.036528028547763824, 0.01771806925535202, 0.009480459615588188, 0.01507704146206379, 0.040890514850616455, 0.05145182088017464, 0.021891290321946144, 0.027799371629953384, 0.05709401145577431, 0.007386161480098963, 0.021902402862906456, 0.021757887676358223, 0.023233674466609955, 0.023715483024716377, 0.014602497220039368, 0.04210027679800987, 0.03691012039780617, 0.014156682416796684, 0.023577431216835976, 0.0027459766715765, 0.025026589632034302, 0.11263972520828247, 0.03317061811685562, 0.05142711102962494, 0.06689679622650146, 0.11585469543933868, 0.009894722141325474, 0.031728968024253845, 0.1269909292459488, 0.03334693983197212, 0.022694328799843788, 0.027165116742253304, 0.021127136424183846, 0.021873004734516144, 0.02293023094534874, 0.01689920946955681, 0.012782953679561615, 0.014503211714327335, 0.022706689313054085, 0.01404094509780407, 0.03121998906135559, 0.004888508468866348, 0.00803717877715826, 0.006753263995051384, 0.006192071828991175, 0.0058339787647128105, 0.00486427778378129, 0.00575187848880887, 0.005801534745842218, 0.002795791020616889, 0.0036300092469900846, 0.0035986867733299732, 0.002918998012319207, 0.010540719144046307, 0.0045805382542312145, 0.0216162521392107, 0.006153212394565344, 0.004587393254041672, 0.003941821400076151, 0.006830172147601843, 0.0138761131092906, 0.003988956101238728, 0.005147469695657492, 0.004291373770684004, 0.04337214678525925] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 451.69 minutes
