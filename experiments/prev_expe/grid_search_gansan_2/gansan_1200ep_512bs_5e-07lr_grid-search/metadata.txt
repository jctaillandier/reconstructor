Epochs: 1200 
 
Total of 10 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 1043 
 
Average lowest loss: 0.0291002868879132151043 
 
Lowest lost Generated:
 [0.03741257265210152, 0.04190093278884888, 0.04498037323355675, 0.1603960394859314, 0.18404948711395264, 0.04535766690969467, 0.01838112436234951, 0.04422210901975632, 0.032422591000795364, 0.021801188588142395, 0.03750528022646904, 0.07210813462734222, 0.021420162171125412, 0.02943572774529457, 0.019969098269939423, 0.048610083758831024, 0.034627560526132584, 0.03666505590081215, 0.017692334949970245, 0.008198782801628113, 0.015889788046479225, 0.037904396653175354, 0.05053103715181351, 0.023178830742836, 0.030725916847586632, 0.02538362704217434, 0.004866527393460274, 0.01724322699010372, 0.024625374004244804, 0.026358196511864662, 0.02485317923128605, 0.013585813343524933, 0.03455066680908203, 0.03642924875020981, 0.017378633841872215, 0.12793660163879395, 0.0048242732882499695, 0.04707011580467224, 0.0264887697994709, 0.032884322106838226, 0.04905691742897034, 0.06912973523139954, 0.021917417645454407, 0.011878518387675285, 0.028045257553458214, 0.12761099636554718, 0.03399873524904251, 0.024373261258006096, 0.021746007725596428, 0.037587471306324005, 0.028353461995720863, 0.023836253210902214, 0.014229878783226013, 0.01591283455491066, 0.034189458936452866, 0.023920796811580658, 0.010254519060254097, 0.028822552412748337, 0.003665411612018943, 0.009876905009150505, 0.008544093929231167, 0.007191120646893978, 0.005890375468879938, 0.00461039412766695, 0.01175509300082922, 0.005054234527051449, 0.003307269187644124, 0.002283290261402726, 0.005032314918935299, 0.005844845902174711, 0.00740081537514925, 0.004959765821695328, 0.018770892173051834, 0.004330664407461882, 0.003041809191927314, 0.005234358366578817, 0.005606256425380707, 0.008418510667979717, 0.004402726888656616, 0.005992673337459564, 0.006048757582902908, 0.05423201993107796] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 5e-07 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 649.03 minutes
