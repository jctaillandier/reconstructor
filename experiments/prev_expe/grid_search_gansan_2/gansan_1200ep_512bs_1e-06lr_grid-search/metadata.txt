Epochs: 1200 
 
Total of 10 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 1176 
 
Average lowest loss: 0.02682727417431591176 
 
Lowest lost Generated:
 [0.031120477244257927, 0.0527595579624176, 0.03205713629722595, 0.16203369200229645, 0.18495775759220123, 0.032783329486846924, 0.03372795507311821, 0.01920260488986969, 0.025196803733706474, 0.016575030982494354, 0.040294989943504333, 0.025913478806614876, 0.02595219388604164, 0.01464302558451891, 0.019542217254638672, 0.017031438648700714, 0.034543294459581375, 0.04019619897007942, 0.018389971926808357, 0.007927213795483112, 0.01890256628394127, 0.03706708177924156, 0.0347963310778141, 0.031502772122621536, 0.04959241300821304, 0.02059136889874935, 0.009615899063646793, 0.01858273707330227, 0.02334127575159073, 0.022322792559862137, 0.02204359695315361, 0.020308777689933777, 0.06561596691608429, 0.013010744005441666, 0.012995933182537556, 0.02686041034758091, 0.0061584217473864555, 0.02422701008617878, 0.02106647938489914, 0.033551499247550964, 0.04954269155859947, 0.07118039578199387, 0.048859115689992905, 0.01169545017182827, 0.040737297385931015, 0.10022033005952835, 0.04130086675286293, 0.0397200733423233, 0.021261217072606087, 0.015449829399585724, 0.022468486800789833, 0.027765100821852684, 0.019833393394947052, 0.018418699502944946, 0.014657685533165932, 0.021861553192138672, 0.016201352700591087, 0.020612966269254684, 0.00844980962574482, 0.010911177843809128, 0.011115025728940964, 0.009213396348059177, 0.013762235641479492, 0.008209077641367912, 0.012543928809463978, 0.009301206097006798, 0.012509169057011604, 0.005092445760965347, 0.006679355166852474, 0.007912533357739449, 0.009709064848721027, 0.007124520838260651, 0.014911558479070663, 0.008147495798766613, 0.00664104986935854, 0.008610345423221588, 0.009457126259803772, 0.009658840484917164, 0.008344851434230804, 0.00596021581441164, 0.008388940244913101, 0.03839416056871414] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 652.24 minutes
