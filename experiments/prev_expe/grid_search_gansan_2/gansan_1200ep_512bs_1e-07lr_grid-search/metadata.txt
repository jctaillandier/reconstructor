Epochs: 1200 
 
Total of 14 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 1129 
 
Average lowest loss: 0.049074802899778611129 
 
Lowest lost Generated:
 [0.12116670608520508, 0.0922476202249527, 0.10594745725393295, 0.1593896746635437, 0.18144969642162323, 0.09510453790426254, 0.031489260494709015, 0.04669510945677757, 0.0602785162627697, 0.0365198589861393, 0.032463882118463516, 0.0733867660164833, 0.07493149489164352, 0.039961010217666626, 0.08842457830905914, 0.048774462193250656, 0.032211434096097946, 0.037173736840486526, 0.014541907235980034, 0.008635764941573143, 0.015164933167397976, 0.03725865110754967, 0.04728395491838455, 0.18020275235176086, 0.06603721529245377, 0.054288350045681, 0.0033043420407921076, 0.016225790604948997, 0.2199123650789261, 0.03238166123628616, 0.039111752063035965, 0.012628071941435337, 0.05213518813252449, 0.03353751823306084, 0.030739676207304, 0.12386446446180344, 0.006339625455439091, 0.1382855772972107, 0.13314740359783173, 0.03136109188199043, 0.04608333483338356, 0.06501056253910065, 0.11220791935920715, 0.006785443518310785, 0.1386900097131729, 0.12865762412548065, 0.033262621611356735, 0.02770862728357315, 0.045575372874736786, 0.029698338359594345, 0.15934155881404877, 0.05385398119688034, 0.0475325807929039, 0.013176520355045795, 0.03460732102394104, 0.062314026057720184, 0.011883427388966084, 0.1164959967136383, 0.0015762678813189268, 0.009280059486627579, 0.004101910628378391, 0.004025842994451523, 0.003975067287683487, 0.005937156733125448, 0.007005967665463686, 0.005247463006526232, 0.003580644493922591, 0.0030908193439245224, 0.004478831775486469, 0.0016575076151639223, 0.006130563095211983, 0.006936739664524794, 0.022783225402235985, 0.0020736977458000183, 0.003497700672596693, 0.002238556509837508, 0.006028229370713234, 0.007652234751731157, 0.0012118720915168524, 0.002088668756186962, 0.001799711026251316, 0.1208459734916687] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-07 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 578.84 minutes
