Epochs: 1200 
 
Total of 12 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 1194 
 
Average lowest loss: 0.0508566828112390551194 
 
Lowest lost Generated:
 [0.09423702955245972, 0.0852120891213417, 0.12062095105648041, 0.1580219864845276, 0.18291839957237244, 0.1017138659954071, 0.03083244152367115, 0.04208177328109741, 0.05737338960170746, 0.031801339238882065, 0.03435433283448219, 0.07468307763338089, 0.06435076892375946, 0.03980446234345436, 0.08938945084810257, 0.0481046624481678, 0.029400000348687172, 0.03686485067009926, 0.01877897046506405, 0.011308948509395123, 0.014060099609196186, 0.03485437110066414, 0.04797383397817612, 0.17954270541667938, 0.334063321352005, 0.05613134056329727, 0.004328424111008644, 0.021291103214025497, 0.22053208947181702, 0.035218290984630585, 0.04073838144540787, 0.016207532957196236, 0.037019237875938416, 0.03502672538161278, 0.02818032167851925, 0.12456312030553818, 0.005974450148642063, 0.14019277691841125, 0.13207587599754333, 0.032901205122470856, 0.051994431763887405, 0.06676237285137177, 0.11173173785209656, 0.007258047349750996, 0.14399635791778564, 0.1250772625207901, 0.031068721786141396, 0.02977803722023964, 0.03795037791132927, 0.035498060286045074, 0.031546760350465775, 0.05325670912861824, 0.03680906072258949, 0.015924803912639618, 0.031188717111945152, 0.09301744401454926, 0.012689201161265373, 0.1246534213423729, 0.0018706821138039231, 0.008142697624862194, 0.003910338971763849, 0.004921401385217905, 0.006140957120805979, 0.00556283351033926, 0.0067306882701814175, 0.002512207953259349, 0.004018235020339489, 0.005487387999892235, 0.005514135118573904, 0.002451889915391803, 0.007399264723062515, 0.008047315292060375, 0.02190227061510086, 0.005737624131143093, 0.0058870562352240086, 0.002578896237537265, 0.004248286597430706, 0.005871520843356848, 0.00393221341073513, 0.004184025339782238, 0.0021104239858686924, 0.10815611481666565] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-07 
Number Epochs: 1200 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 783.77 minutes
