Epochs: 500 
 
Total of 13 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 495 
 
Lowest lost Generated:
 [0.06079081818461418, 0.04682624712586403, 0.05539005249738693, 0.15727727115154266, 0.1801355630159378, 0.06987408548593521, 0.024004671722650528, 0.02839437499642372, 0.027428854256868362, 0.014883107505738735, 0.031884655356407166, 0.07333403825759888, 0.03491606563329697, 0.0391760990023613, 0.022548427805304527, 0.05105149373412132, 0.029120542109012604, 0.037617724388837814, 0.01603333279490471, 0.007611369248479605, 0.013197192922234535, 0.035269904881715775, 0.04638282209634781, 0.02448480762541294, 0.029736187309026718, 0.05439364165067673, 0.0026308593805879354, 0.017553381621837616, 0.22067458927631378, 0.023000702261924744, 0.026004083454608917, 0.015276864171028137, 0.027779147028923035, 0.03216400742530823, 0.019849970936775208, 0.12396956235170364, 0.0009426450124010444, 0.13744138181209564, 0.13153862953186035, 0.034490104764699936, 0.04738333076238632, 0.06414055079221725, 0.11424911022186279, 0.00883022602647543, 0.13909688591957092, 0.12533913552761078, 0.03348076343536377, 0.02547742798924446, 0.024505387991666794, 0.030166326090693474, 0.025147229433059692, 0.03254708647727966, 0.0504356287419796, 0.011785046197474003, 0.015651308000087738, 0.017575901001691818, 0.009265545755624771, 0.04700595885515213, 0.0042449962347745895, 0.0044181630946695805, 0.006044697482138872, 0.004168802872300148, 0.004074843600392342, 0.004030933137983084, 0.006671627517789602, 0.004122490994632244, 0.0013898828765377402, 0.002490925369784236, 0.0027843264397233725, 0.003841651836410165, 0.0027088646311312914, 0.0033163686748594046, 0.016019368544220924, 0.003942947369068861, 0.0032260557636618614, 0.0017902579857036471, 0.003497155150398612, 0.0071905748918652534, 0.0017029696609824896, 0.00215205573476851, 0.0016362698515877128, 0.06481575220823288] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 124.43 minutes
