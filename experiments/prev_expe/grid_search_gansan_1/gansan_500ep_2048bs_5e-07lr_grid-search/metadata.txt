Epochs: 500 
 
Total of 15 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 499 
 
Lowest lost Generated:
 [0.10964684188365936, 0.08343735337257385, 0.09752514958381653, 0.1571449190378189, 0.1852235049009323, 0.10075362771749496, 0.03804586082696915, 0.0433296374976635, 0.05726684629917145, 0.03258710354566574, 0.031948331743478775, 0.06080887094140053, 0.06387782841920853, 0.03840331733226776, 0.08506858348846436, 0.04638507217168808, 0.029341841116547585, 0.0390547476708889, 0.013612051494419575, 0.005531321279704571, 0.013547960668802261, 0.03943420946598053, 0.0490034781396389, 0.17090022563934326, 0.22796189785003662, 0.053926464170217514, 0.002524780109524727, 0.01910862699151039, 0.2191162258386612, 0.14771181344985962, 0.048244863748550415, 0.016579700633883476, 0.05390869453549385, 0.03651508316397667, 0.02867550030350685, 0.08678071200847626, 0.0010305116884410381, 0.13836733996868134, 0.13160106539726257, 0.03253042697906494, 0.045716479420661926, 0.06999368220567703, 0.11406423151493073, 0.006951204035431147, 0.14146967232227325, 0.12369793653488159, 0.034508734941482544, 0.03290894255042076, 0.047335125505924225, 0.03306909650564194, 0.05254524573683739, 0.05399831756949425, 0.012601911090314388, 0.014022267423570156, 0.03466974198818207, 0.08632893115282059, 0.011265371926128864, 0.14558586478233337, 0.004257614258676767, 0.008588110096752644, 0.0037772406358271837, 0.007543237879872322, 0.0032442014198750257, 0.0035597695969045162, 0.009943481534719467, 0.002964633284136653, 0.005172505509108305, 0.0032861419022083282, 0.006155658513307571, 0.00293109193444252, 0.001025066478177905, 0.0056441109627485275, 0.019421488046646118, 0.0018600048497319221, 0.0018410425400361419, 0.0038304165937006474, 0.001732087810523808, 0.005006962921470404, 0.005520541686564684, 0.004454349633306265, 0.0033785225823521614, 0.12340636551380157] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 5e-07 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 82.72 minutes
