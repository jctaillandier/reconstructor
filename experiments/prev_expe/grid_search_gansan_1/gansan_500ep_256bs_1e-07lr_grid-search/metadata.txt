Epochs: 500 
 
Total of 10 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 498 
 
Lowest lost Generated:
 [0.12428317964076996, 0.12242110818624496, 0.11870305240154266, 0.15764082968235016, 0.18043208122253418, 0.08223322778940201, 0.025027558207511902, 0.03723600506782532, 0.07292696833610535, 0.059353675693273544, 0.033973902463912964, 0.07173244655132294, 0.15741024911403656, 0.038131728768348694, 0.0865366980433464, 0.04796620458364487, 0.030974462628364563, 0.0357142835855484, 0.015906302258372307, 0.010505877435207367, 0.014235866256058216, 0.03725096583366394, 0.047027215361595154, 0.18033184111118317, 0.33444374799728394, 0.054290857166051865, 0.0028906266670674086, 0.020801566541194916, 0.22020359337329865, 0.14671893417835236, 0.058844003826379776, 0.012583430856466293, 0.043709371238946915, 0.035096365958452225, 0.03084620274603367, 0.12616854906082153, 0.0015505262417718768, 0.1395140290260315, 0.13259780406951904, 0.033196624368429184, 0.04630729928612709, 0.06815323978662491, 0.11354681849479675, 0.007139714900404215, 0.14052072167396545, 0.12381112575531006, 0.031229058280587196, 0.02709980681538582, 0.2560955584049225, 0.030807264149188995, 0.060266345739364624, 0.10806504637002945, 0.026873480528593063, 0.014840885996818542, 0.03384896367788315, 0.09467869251966476, 0.009131291881203651, 0.18076643347740173, 0.0018148429226130247, 0.007742238696664572, 0.0058944206684827805, 0.0034590689465403557, 0.006518317852169275, 0.007357491645962, 0.005807817913591862, 0.004906170070171356, 0.002670612186193466, 0.0012910936493426561, 0.004098822828382254, 0.0031020978931337595, 0.0032130274921655655, 0.003594541223719716, 0.01989990845322609, 0.004573376849293709, 0.001993879908695817, 0.0023525881115347147, 0.003520186524838209, 0.009959360584616661, 0.0016706844326108694, 0.006601335946470499, 0.0040033007971942425, 0.11594756692647934] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-07 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 180.98 minutes
