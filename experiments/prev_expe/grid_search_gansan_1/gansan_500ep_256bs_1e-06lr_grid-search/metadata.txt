Epochs: 500 
 
Total of 12 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 423 
 
Lowest lost Generated:
 [0.02691013365983963, 0.03999800980091095, 0.031821589916944504, 0.15963657200336456, 0.18622301518917084, 0.032198674976825714, 0.01927655003964901, 0.01635906472802162, 0.024044087156653404, 0.016199564561247826, 0.035703666508197784, 0.01167901512235403, 0.01789412833750248, 0.021589819341897964, 0.02265746146440506, 0.011657578870654106, 0.03211832419037819, 0.03858740255236626, 0.021180154755711555, 0.010056727565824986, 0.015423774719238281, 0.03753247857093811, 0.05377170816063881, 0.03359029069542885, 0.027552912011742592, 0.02353733405470848, 0.007673193700611591, 0.020157381892204285, 0.024938788264989853, 0.02092810906469822, 0.018278026953339577, 0.013267011381685734, 0.022099405527114868, 0.012277968227863312, 0.011602873913943768, 0.01959575153887272, 0.00644201273098588, 0.03240222856402397, 0.029341401532292366, 0.032669540494680405, 0.04853304475545883, 0.06900900602340698, 0.029403015971183777, 0.011947057209908962, 0.044233813881874084, 0.10009930282831192, 0.0361185260117054, 0.015449943020939827, 0.017382865771651268, 0.038064971566200256, 0.025324854999780655, 0.027372611686587334, 0.011316944845020771, 0.013511350378394127, 0.012974761426448822, 0.015168152749538422, 0.019256850704550743, 0.022918788716197014, 0.007429043762385845, 0.008298110216856003, 0.007611461915075779, 0.010410281829535961, 0.004050370305776596, 0.0075479415245354176, 0.010514384135603905, 0.007289839908480644, 0.006484814453870058, 0.005394969135522842, 0.008179056458175182, 0.009298867546021938, 0.004055916331708431, 0.009188218042254448, 0.01729016751050949, 0.0061866105534136295, 0.007270904257893562, 0.006056831683963537, 0.006314846687018871, 0.010618653148412704, 0.004704614635556936, 0.008161409758031368, 0.004663622006773949, 0.037578046321868896] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 267.17 minutes
