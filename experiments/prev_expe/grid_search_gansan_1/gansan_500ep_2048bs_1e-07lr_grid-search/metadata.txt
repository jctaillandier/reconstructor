Epochs: 500 
 
Total of 14 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 499 
 
Lowest lost Generated:
 [0.1395542323589325, 0.0802728533744812, 0.13781166076660156, 0.1554383486509323, 0.17944283783435822, 0.15142692625522614, 0.33048906922340393, 0.25555720925331116, 0.33669188618659973, 0.24228623509407043, 0.031044168397784233, 0.06943081319332123, 0.279978483915329, 0.04712513089179993, 0.08532219380140305, 0.045583754777908325, 0.03173653408885002, 0.035150375217199326, 0.012790997512638569, 0.004943002015352249, 0.0210284236818552, 0.03566286340355873, 0.046416837722063065, 0.17930901050567627, 0.32701873779296875, 0.059088584035634995, 0.002616394544020295, 0.015498645603656769, 0.21848028898239136, 0.14277660846710205, 0.09918735921382904, 0.011396587826311588, 0.2029682695865631, 0.03181609511375427, 0.027440136298537254, 0.12080134451389313, 0.0013619497185572982, 0.13618595898151398, 0.12754878401756287, 0.03630072996020317, 0.046011343598365784, 0.06423220783472061, 0.11178968846797943, 0.006318120285868645, 0.1372535079717636, 0.1302800476551056, 0.031305622309446335, 0.06258365511894226, 0.24093309044837952, 0.03085746429860592, 0.1545398235321045, 0.10384868085384369, 0.055553220212459564, 0.011637427844107151, 0.03642616048455238, 0.09295285493135452, 0.015070135705173016, 0.24286366999149323, 0.0008723729406483471, 0.011667187325656414, 0.011966345831751823, 0.009558291174471378, 0.0021203358191996813, 0.0031065226066857576, 0.004250820726156235, 0.00418354757130146, 0.0022110515274107456, 0.004747325554490089, 0.0007396459113806486, 0.007948855869472027, 0.0007411142578348517, 0.005092267878353596, 0.022420380264520645, 0.010368089191615582, 0.009054085239768028, 0.005127330776304007, 0.007185172289609909, 0.004632475320249796, 0.000636767887044698, 0.0024235504679381847, 0.009406516328454018, 0.34069114923477173] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-07 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 83.86 minutes
