Epochs: 500 
 
Total of 13 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 451 
 
Lowest lost Generated:
 [0.0930098444223404, 0.08335348963737488, 0.043151747435331345, 0.15902617573738098, 0.18319763243198395, 0.0792379304766655, 0.01872333325445652, 0.027341658249497414, 0.02769140526652336, 0.019378889352083206, 0.03256348520517349, 0.07275603711605072, 0.03522138670086861, 0.04035310447216034, 0.01991346850991249, 0.04839446023106575, 0.03055473044514656, 0.03605274483561516, 0.015869207680225372, 0.005786724854260683, 0.013363881967961788, 0.034176625311374664, 0.0487317219376564, 0.027076072990894318, 0.02871149405837059, 0.05453130975365639, 0.004449969623237848, 0.017833497375249863, 0.21585683524608612, 0.02028706856071949, 0.024215197190642357, 0.012724270112812519, 0.022563708946108818, 0.03304281830787659, 0.03209467977285385, 0.12665778398513794, 0.002878805622458458, 0.13507680594921112, 0.13255685567855835, 0.031817834824323654, 0.04716619849205017, 0.06715472787618637, 0.11413262784481049, 0.007670023012906313, 0.13564050197601318, 0.12644106149673462, 0.030753273516893387, 0.023188218474388123, 0.01997700333595276, 0.02967255376279354, 0.01824413426220417, 0.016337646171450615, 0.014358666725456715, 0.013703499920666218, 0.030657222494482994, 0.09376383572816849, 0.01109185442328453, 0.03873666375875473, 0.004941485356539488, 0.007394777610898018, 0.005696265026926994, 0.003934953361749649, 0.0038392245769500732, 0.007090891245752573, 0.007115442771464586, 0.004545226227492094, 0.0031801890581846237, 0.001308691338635981, 0.0029428366106003523, 0.002217206172645092, 0.0016246505547314882, 0.003123404923826456, 0.021520288661122322, 0.004050306510180235, 0.0025361895095556974, 0.0018365903524681926, 0.005261660553514957, 0.00777392229065299, 0.003812731709331274, 0.005312196910381317, 0.0020094190258532763, 0.0562044195830822] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 5e-07 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-07
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 125.59 minutes
