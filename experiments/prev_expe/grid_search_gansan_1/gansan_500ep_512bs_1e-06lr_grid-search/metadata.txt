Epochs: 500 
 
Total of 8 / 82 are now closer to original data (L1 distance). 
 
Epoch of lowest loss: 493 
 
Lowest lost Generated:
 [0.03040921315550804, 0.041660554707050323, 0.034444548189640045, 0.16126945614814758, 0.18475370109081268, 0.03914932161569595, 0.02444528602063656, 0.017872966825962067, 0.0386137031018734, 0.0520886667072773, 0.015760965645313263, 0.015925833955407143, 0.019133923575282097, 0.015032888390123844, 0.02232474833726883, 0.01632644049823284, 0.0360090434551239, 0.03870749846100807, 0.01634032279253006, 0.011262824758887291, 0.01861032471060753, 0.03761996701359749, 0.05273284390568733, 0.02771027199923992, 0.02583276480436325, 0.019305706024169922, 0.005804343614727259, 0.020466521382331848, 0.024741115048527718, 0.03233093395829201, 0.025233903899788857, 0.018858974799513817, 0.03691815584897995, 0.03741922602057457, 0.012340202927589417, 0.029234690591692924, 0.00864478014409542, 0.03292899206280708, 0.13463106751441956, 0.03785838559269905, 0.05130411684513092, 0.06679505109786987, 0.021577682346105576, 0.01094605028629303, 0.026651112362742424, 0.1272270679473877, 0.03744048625230789, 0.021234801039099693, 0.022633833810687065, 0.016441399231553078, 0.0374436192214489, 0.022277643904089928, 0.011847174726426601, 0.014603820629417896, 0.013099845498800278, 0.023440944030880928, 0.012711768038570881, 0.035084087401628494, 0.0029670679941773415, 0.009174096398055553, 0.009670447558164597, 0.005386818666011095, 0.007693439722061157, 0.006275219842791557, 0.006314976140856743, 0.006254853680729866, 0.0027048911433666945, 0.0026144813746213913, 0.0040283408015966415, 0.003315573325380683, 0.006761269178241491, 0.004928277339786291, 0.020846325904130936, 0.004564968403428793, 0.0050833337008953094, 0.008703229948878288, 0.004319984465837479, 0.008636506274342537, 0.007673713844269514, 0.002860455773770809, 0.0034890274982899427, 0.04391074553132057] 
 
Loss from sanitized data: 
[0.036975961178541183, 0.0962391197681427, 0.031760625541210175, 0.15507377684116364, 0.18011920154094696, 0.029181107878684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000589622650295496, 0.000147405662573874, 0.030512971803545952, 0.07576651126146317, 0.012971698306500912, 0.010465801693499088, 0.016509434208273888, 0.033313680440187454, 0.025058962404727936, 0.002063679276034236, 0.00294811325147748, 0.003685141447931528, 0.001916273613460362, 0.015182782895863056, 0.001179245300590992, 0.0, 0.000589622650295496, 0.0, 0.0, 0.0, 0.0, 0.006043632049113512, 0.01606721617281437, 0.00987617950886488, 0.005454009398818016, 0.06824882328510284, 0.048791274428367615, 0.06353183835744858, 0.004127358552068472, 0.012382075190544128, 0.00972877349704504, 0.11512382328510284, 0.03419811278581619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00795990601181984, 0.0, 0.004716981202363968, 0.00795990601181984, 0.001179245300590992, 0.000589622650295496, 0.012382075190544128, 0.00397995300590992, 0.002653301926329732, 0.001179245300590992, 0.002653301926329732, 0.003685141447931528, 0.016951650381088257, 0.000884433975443244, 0.000147405662573874, 0.000884433975443244, 0.002358490601181984, 0.000442216987721622, 0.001916273613460362, 0.006485849153250456, 0.002211084822192788, 0.000294811325147748, 0.004569575656205416, 0.001179245300590992, 0.005159198306500912, 0.000294811325147748, 0.001916273613460362, 0.000442216987721622, 0.017688678577542305] 

 
 Learning Rate: 1e-06 
Number Epochs: 500 
weight decay: 0
Training Loss: L1Loss()
Test Loss: L1Loss() 
self.self.optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
)
Model Architecture: Autoencoder(
  (encoder): Sequential(
    (0): Linear(in_features=82, out_features=82, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=82, out_features=82, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=82, out_features=82, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
)
Training completed in: 185.88 minutes
